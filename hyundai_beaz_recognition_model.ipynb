{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkvBfSi4btdNjjdlmfBlAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwak-Jiwon/car-recognition-model/blob/main/hyundai_beaz_recognition_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code\n",
        "\n"
      ],
      "metadata": {
        "id": "LyCEw3cVI_tI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "①. 프로젝트의 motivation\n",
        "이 프로그램은 차량 이미지를 통해 차량의 제조사를 도출하는 프로그램입니다. 이 프로그램을 통해 교통 법규 위반 차량을 더 쉽게 색출할 수 있습니다. 속도 위반, 신호 위반 차량을 잡는 데에는 경찰 단속, CCTV 가 있습니다. 이 중 CCTV를 통해 교통 법규 위반 차량을 단속하는 경우가 많습니다. 만약, 교통 법규를 어긴 차량이 CCTV 에 찍히면, 이 차량의 정보를 등록된 정보와, 해당 모델을 통해 도출한 차량 제조사 정보와 대칭하면 차량 단속을 더 정확히 할 수 있습니다."
      ],
      "metadata": {
        "id": "rG0oCa9iNAs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "②. 프로그램의 데이터 패턴 종류\n",
        "해당 프로그램은 제가 직접 촬영한 차량 이미지 데이터로 동작하며 이미지 프레임을 딥러닝합니다.\n",
        "**이미지 데이터는 총 216장이며 모두 제가 핸드폰으로 사진을 찍어 생성한 데이터입니다. **"
      ],
      "metadata": {
        "id": "lGdKZ__AOqA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "③. 데이터 수집 과정 및 augmentation 사용 기술\n",
        "데이터는 직접 카메라로 촬영하여 생성한 차량 데이터 입니다. 총 216장으로, 벤츠 차량 63장, 현대차량 153장입니다.\n",
        "수집한 데이터가 적어, ImageDataGenerator를 통해 데이터를 변형하여 확장하였습니다. 기울기를 0.2로 설정하고, 이미지를 일부 확대하고 가로로 뒤집고 좌우상하 이동하고 밝기를 조절하였습니다."
      ],
      "metadata": {
        "id": "d21Bbhq3PWPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "④. 전이학습이나, 타인의 데이터를 추가한 경우, 그 데이터에 대한 설명\n",
        "데이터가 적은 점을 고려하여 전이학습을 사용하였습니다. 제가 사용한 모델은 GoogleNet의 InceptionV3입니다. 해당 모델은 ImageNet 데이터 세트에서 정확도가 78.1% 이상인 것으로 입증된 영상 인식 모델입니다. 모델은 컨볼루션, 평균/최대 풀링, 드롭아웃 완전 연결형 레이어를 포함한 대칭 및 비대칭 구성요소로 구성되어 있습니다. 손실은 소프트맥스를 통해 계산됩니다."
      ],
      "metadata": {
        "id": "PgPOkxM2RD3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑤. 데이터의 크기 및 개수, 용량, 데이터 크기의 타당성 (딥러닝 가능성)\n",
        "제가 생성한 이미지 데이터는 차량 전면부 데이터 총 156장이며, 용량은 벤츠 97.55MB, 현대 397MB입니다. 데이터를 생성하며 전이학습과 argumentation 기술을 사용할거라 100장 정도면 충분할 것이라 생각하였지만, 실제 코딩을 해보니 이 생각은 저의 착각임을 깨달았습니다. 이후, 데이터를 추가하였지만 이조차도 부족하였습니다. 다음번에는 하나의 카테고리 당 적어도 300장 이상은 데이터를 마련해야겠다고 생각하였습니다."
      ],
      "metadata": {
        "id": "7xn2VeiWS8Fl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑥. 본인의 딥러닝 프로그래밍에 대한 자세한 설명 (딥네트웍 구조 등)\n",
        "우선, git repository의 제조사 두 개의 폴더로 나누어 저장된 이미지 파일을 불러옵니다. ImageDataGenerator을 통해 데이터를 증강하며 객체를 생성한 후 flow_from_directory를 통해 Numpy Array Iterator로 생성 및 변환해준다. 이미지를 224x224 픽셀의 크기 리사이징하고, 배치 크기는 32로 지정합니다. 이 모델은 2개의 카테고리 중 구별하므로 바이너리로 지정합니다. InceptionV3의 미리 학습된 가중치를 불러옵니다. GlobalAveragePooling2D를 통해 차원을 축소하고 오버피팅을 위해 dropout 값을 지정합니다. 모델 컴파일 과정의 옵티마이저는 adam을 사용하였으며, adam에서 가장 좋은 학습률은 0.001이라고 알려져 있어 학습률을 0.001로 지정하였습니다. 이진 분류이므로 손실함수는 binary_crossentropy로 지정하였습니다. Dense를 통해 10개의 뉴런을 가진 완전 연결층 생성한다.\n",
        "얼리 스타핑을 통해 val_loss가 5번 연속 높아지면 학습을 멈추고 결과를 저장하도록 하고 model fit단계에서 epochs을 20으로 지정하여 학습을 20번 진행하도록 함.\n",
        "layer.trainable = False을 통해 전이학습을 위해 가져온 모델의 가중치가 업데이트 되지 않도록 설정함."
      ],
      "metadata": {
        "id": "iTATOYalT2Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑦. 결과에 대한 충분한 분석과 설명 (도표나, 결과 화면을 캡춰해서 제시)\n",
        "결과는 정확도 0.29로 계속 정확도, 손실값이 같게 나왔습니다. 저는 이 이유를 데이터의 수가 충분하지 않아 발생한 오버피팅이라고 생각합니다. 따라서,  dropout을 지정하고, 학습률 값을 변경하고, 이미지 변형을 통해 데이터를 늘려보았지만, 오버피팅은 계속되었습니다. 오버피팅을 막기 위해서는 각 모델에 대한 더 많은 데이터가 3배 이상 필요할 것 같습니다."
      ],
      "metadata": {
        "id": "MoWS0dH3d1b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑧. 프로젝트를 위해 활용한 자료나, 동영상 링크\n",
        "https://keras.io/api/data_loading/image/\n",
        "Inception v3 고급 가이드\n",
        "https://cloud.google.com/tpu/docs/inception-v3-advanced?hl=ko\n",
        "\n",
        "flow_from_directory 사용법\n",
        "https://techblog-history-younghunjo1.tistory.com/261"
      ],
      "metadata": {
        "id": "zUj54zI6Q8zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑨. 본 프로젝트를 통해 느낀점\n",
        "데이터 수집 과정이 정말 중요함을 느꼈습니다. 데이터의 크기, 데이터의 질이 중요함을 느꼈고 앞으로 딥러닝 모델을 구현할 때는 더 충분한 데이터를 마련해야겠다는 생각을 하였습니다. 여러모로 아쉬움이 많이 남는 결과가 나와서 시험기간이 끝나면 다시 실패 요인을 분석하고 새로운 모델을 구현해볼 듯 합니다. 그래도 그동안 수업 시간에 배운 내용을 실제로 구현해보니 즐거웠고, 신기했습니다."
      ],
      "metadata": {
        "id": "hpgQbWGpu_EZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑩. 프로젝트 수행 과정에 대한 간략한 일정 고찰\n",
        "5월 20일 경부터 10일 정도 차량 사진을 찍어 데이터를 확보한 후 자료 조사를 이틀 간 진행한 후 모델을 구현하였습니다. 과제를 더 일찍 시작하여 더 충분한 시간이 있었다면 더 나은 결과물이 나오지 않았을까 하는 아쉬움이 남았습니다."
      ],
      "metadata": {
        "id": "RNtH4bufvozS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "\n",
        "\n",
        "!git clone https://github.com/Kwak-Jiwon/DPR_imgdata.git\n",
        "\n",
        "\n",
        "train_dir = 'DPR_imgdata/'\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8,1.2],\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "\n",
        "model.save('car_classifier_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSSTsxeMoTCv",
        "outputId": "f03b7ffe-6201-4a18-b718-90cfafba7d4a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DPR_imgdata' already exists and is not an empty directory.\n",
            "Found 174 images belonging to 3 classes.\n",
            "Found 42 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 27s 4s/step - loss: -3.1706 - accuracy: 0.2816 - val_loss: -7.1902 - val_accuracy: 0.2857\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 19s 4s/step - loss: -10.0054 - accuracy: 0.2931 - val_loss: -13.8700 - val_accuracy: 0.2857\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: -16.4425 - accuracy: 0.2931 - val_loss: -21.2664 - val_accuracy: 0.2857\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 17s 3s/step - loss: -23.5426 - accuracy: 0.2931 - val_loss: -29.5266 - val_accuracy: 0.2857\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: -31.8044 - accuracy: 0.2931 - val_loss: -37.1571 - val_accuracy: 0.2857\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 17s 3s/step - loss: -40.9257 - accuracy: 0.2931 - val_loss: -46.8616 - val_accuracy: 0.2857\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 17s 3s/step - loss: -48.8960 - accuracy: 0.2931 - val_loss: -55.2201 - val_accuracy: 0.2857\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 19s 3s/step - loss: -56.7636 - accuracy: 0.2931 - val_loss: -63.2915 - val_accuracy: 0.2857\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 17s 3s/step - loss: -67.3512 - accuracy: 0.2931 - val_loss: -71.9154 - val_accuracy: 0.2857\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 19s 3s/step - loss: -76.6152 - accuracy: 0.2931 - val_loss: -83.5117 - val_accuracy: 0.2857\n"
          ]
        }
      ]
    }
  ]
}